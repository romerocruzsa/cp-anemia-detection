{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for file handling, data manipulation, and visualization\n",
    "import os \n",
    "import random\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import libraries for working with images and transformations\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "\n",
    "# Import PyTorch modules for model building, data handling, and evaluation\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchinfo import summary\n",
    "\n",
    "# Import libraries for machine learning metrics and model evaluation\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve\n",
    "import torchmetrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMAGE_ID</th>\n",
       "      <th>HB_LEVEL</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Age(Months)</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>REMARK</th>\n",
       "      <th>HOSPITAL</th>\n",
       "      <th>CITY/TOWN</th>\n",
       "      <th>MUNICIPALITY/DISTRICT</th>\n",
       "      <th>REGION</th>\n",
       "      <th>COUNTRY</th>\n",
       "      <th>SEVERITY_ONEHOT</th>\n",
       "      <th>REMARK_ONEHOT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_001</td>\n",
       "      <td>9.80</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>Anemic</td>\n",
       "      <td>Nkawie-Toase Government Hospital</td>\n",
       "      <td>Nkawie-Toase</td>\n",
       "      <td>Atwima Nwabiagya South</td>\n",
       "      <td>Ashanti</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_002</td>\n",
       "      <td>9.90</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Anemic</td>\n",
       "      <td>Ejusu Government Hospital</td>\n",
       "      <td>Ejusu</td>\n",
       "      <td>Ejusu Municipality</td>\n",
       "      <td>Ashanti</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_003</td>\n",
       "      <td>11.10</td>\n",
       "      <td>Non-Anemic</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-anemic</td>\n",
       "      <td>Ahmadiyya Muslim Hospital</td>\n",
       "      <td>Tachiman</td>\n",
       "      <td>Techiman Municipality</td>\n",
       "      <td>Bono-East</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_004</td>\n",
       "      <td>12.50</td>\n",
       "      <td>Non-Anemic</td>\n",
       "      <td>12</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-anemic</td>\n",
       "      <td>Ahmadiyya Muslim Hospital</td>\n",
       "      <td>Tachiman</td>\n",
       "      <td>Techiman Municipality</td>\n",
       "      <td>Bono-East</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_005</td>\n",
       "      <td>9.90</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Anemic</td>\n",
       "      <td>Sunyani Municipal Hospital</td>\n",
       "      <td>Sunyani</td>\n",
       "      <td>Sunyani Municipality</td>\n",
       "      <td>Bono</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>[0, 0, 1, 0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>Image_706</td>\n",
       "      <td>12.80</td>\n",
       "      <td>Non-Anemic</td>\n",
       "      <td>48</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-anemic</td>\n",
       "      <td>Bolgatanga Regional Hospital</td>\n",
       "      <td>Bolgatanga</td>\n",
       "      <td>Bolgatanga Municipality</td>\n",
       "      <td>Upper East</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>Image_707</td>\n",
       "      <td>11.47</td>\n",
       "      <td>Non-Anemic</td>\n",
       "      <td>48</td>\n",
       "      <td>Female</td>\n",
       "      <td>Non-anemic</td>\n",
       "      <td>Ahmadiyya Muslim Hospital</td>\n",
       "      <td>Tachiman</td>\n",
       "      <td>Techiman Municipality</td>\n",
       "      <td>Bono-East</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>Image_708</td>\n",
       "      <td>11.60</td>\n",
       "      <td>Non-Anemic</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-anemic</td>\n",
       "      <td>Komfo Anokye Teaching Hospital</td>\n",
       "      <td>Kumasi</td>\n",
       "      <td>Kumasi Metropolitan</td>\n",
       "      <td>Ashanti</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>Image_709</td>\n",
       "      <td>12.10</td>\n",
       "      <td>Non-Anemic</td>\n",
       "      <td>48</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-anemic</td>\n",
       "      <td>Bolgatanga Regional Hospital</td>\n",
       "      <td>Bolgatanga</td>\n",
       "      <td>Bolgatanga Municipality</td>\n",
       "      <td>Upper East</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>Image_710</td>\n",
       "      <td>11.70</td>\n",
       "      <td>Non-Anemic</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Non-anemic</td>\n",
       "      <td>Ahmadiyya Muslim Hospital</td>\n",
       "      <td>Tachiman</td>\n",
       "      <td>Techiman Municipality</td>\n",
       "      <td>Bono-East</td>\n",
       "      <td>Ghana</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>710 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      IMAGE_ID  HB_LEVEL    Severity  Age(Months)  GENDER      REMARK  \\\n",
       "0    Image_001      9.80    Moderate            6  Female      Anemic   \n",
       "1    Image_002      9.90    Moderate           24    Male      Anemic   \n",
       "2    Image_003     11.10  Non-Anemic           24  Female  Non-anemic   \n",
       "3    Image_004     12.50  Non-Anemic           12    Male  Non-anemic   \n",
       "4    Image_005      9.90    Moderate           24    Male      Anemic   \n",
       "..         ...       ...         ...          ...     ...         ...   \n",
       "705  Image_706     12.80  Non-Anemic           48    Male  Non-anemic   \n",
       "706  Image_707     11.47  Non-Anemic           48  Female  Non-anemic   \n",
       "707  Image_708     11.60  Non-Anemic           60    Male  Non-anemic   \n",
       "708  Image_709     12.10  Non-Anemic           48    Male  Non-anemic   \n",
       "709  Image_710     11.70  Non-Anemic           24    Male  Non-anemic   \n",
       "\n",
       "                             HOSPITAL     CITY/TOWN    MUNICIPALITY/DISTRICT  \\\n",
       "0    Nkawie-Toase Government Hospital  Nkawie-Toase   Atwima Nwabiagya South   \n",
       "1           Ejusu Government Hospital         Ejusu       Ejusu Municipality   \n",
       "2           Ahmadiyya Muslim Hospital      Tachiman    Techiman Municipality   \n",
       "3           Ahmadiyya Muslim Hospital      Tachiman    Techiman Municipality   \n",
       "4          Sunyani Municipal Hospital       Sunyani     Sunyani Municipality   \n",
       "..                                ...           ...                      ...   \n",
       "705      Bolgatanga Regional Hospital    Bolgatanga  Bolgatanga Municipality   \n",
       "706         Ahmadiyya Muslim Hospital      Tachiman    Techiman Municipality   \n",
       "707   Komfo Anokye Teaching Hospital        Kumasi       Kumasi Metropolitan   \n",
       "708      Bolgatanga Regional Hospital    Bolgatanga  Bolgatanga Municipality   \n",
       "709         Ahmadiyya Muslim Hospital      Tachiman    Techiman Municipality   \n",
       "\n",
       "         REGION COUNTRY SEVERITY_ONEHOT  REMARK_ONEHOT  \n",
       "0       Ashanti   Ghana    [0, 0, 1, 0]              1  \n",
       "1       Ashanti   Ghana    [0, 0, 1, 0]              1  \n",
       "2     Bono-East   Ghana    [1, 0, 0, 0]              0  \n",
       "3     Bono-East   Ghana    [1, 0, 0, 0]              0  \n",
       "4          Bono   Ghana    [0, 0, 1, 0]              1  \n",
       "..          ...     ...             ...            ...  \n",
       "705  Upper East   Ghana    [1, 0, 0, 0]              0  \n",
       "706   Bono-East   Ghana    [1, 0, 0, 0]              0  \n",
       "707     Ashanti   Ghana    [1, 0, 0, 0]              0  \n",
       "708  Upper East   Ghana    [1, 0, 0, 0]              0  \n",
       "709   Bono-East   Ghana    [1, 0, 0, 0]              0  \n",
       "\n",
       "[710 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = \"C:\\\\Users\\\\sebastian.cruz6\\\\Workspace\\\\Research\\\\CAWT-URFI\\\\cp-anemia-detection\\\\data\\\\cp-anemia\\\\\"\n",
    "anemic_dir = data_dir+\"Anemic\\\\\"\n",
    "non_anemic_dir = data_dir+\"Non-anemic\\\\\"\n",
    "\n",
    "data_sheet_path = data_dir+\"Anemia_Data_Collection_Sheet.csv\"\n",
    "data_sheet = pd.read_csv(data_sheet_path)\n",
    "\n",
    "# Mapping diagnosis to severity\n",
    "severity_mapping = {\n",
    "    \"Non-Anemic\": [1,0,0,0],\n",
    "    \"Mild\": [0,1,0,0],\n",
    "    \"Moderate\": [0,0,1,0],\n",
    "    \"Severe\": [0,0,0,1],\n",
    "}\n",
    "\n",
    "data_sheet['SEVERITY_ONEHOT'] = data_sheet['Severity'].map(severity_mapping)\n",
    "\n",
    "# Mapping diagnosis to severity\n",
    "remark_mapping = {\n",
    "    \"Non-anemic\": 0,\n",
    "    \"Anemic\": 1\n",
    "}\n",
    "\n",
    "data_sheet['REMARK_ONEHOT'] = data_sheet['REMARK'].map(remark_mapping)\n",
    "display(data_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available, using CPU.\n",
      "Selected device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "# Default device\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Check for CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU.\")\n",
    "\n",
    "print(f\"Selected device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer, cumulative_metrics):\n",
    "    \"\"\"\n",
    "    Training loop for one epoch.\n",
    "    \n",
    "    Parameters:\n",
    "    dataloader (DataLoader): DataLoader containing the training data.\n",
    "    model (torch.nn.Module): PyTorch model to be trained.\n",
    "    loss_fn (callable): Loss function.\n",
    "    optimizer (torch.optim.Optimizer): Optimizer for updating the model parameters.\n",
    "    cumulative_metrics (CumulativeMetrics): Instance of CumulativeMetrics for tracking metrics.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Average loss and average accuracy for the epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    batch_losses = []\n",
    "    batch_acc = []\n",
    "    cumulative_metrics.reset()\n",
    "\n",
    "    for _, (X, y, _) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device).unsqueeze(1)\n",
    "        y = y.to(torch.float32)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "\n",
    "        # logits = model(X)\n",
    "        # probabilities = torch.softmax(logits, dim=1) # Convert logits to probabilities using softmax\n",
    "        # predicted_classes = torch.argmax(probabilities, dim=1) # Get the predicted class (index of the highest probability)\n",
    "        # pred = torch.nn.functional.one_hot(predicted_classes, num_classes=5).float() # Convert class indices to one-hot encoding\n",
    "\n",
    "        loss = loss_fn(pred, y)        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_losses.append(loss.item())        \n",
    "        cumulative_metrics.update(pred, y)\n",
    "    \n",
    "    avg_loss = sum(batch_losses) / len(batch_losses)    \n",
    "    performance_metrics = cumulative_metrics.get_cumulative_metrics()\n",
    "\n",
    "    return avg_loss, performance_metrics\n",
    "\n",
    "def eval(dataloader, model, loss_fn, mode, cumulative_metrics):\n",
    "    \"\"\"\n",
    "    Testing loop to evaluate the model on the test dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    dataloader (DataLoader): DataLoader containing the test data.\n",
    "    model (torch.nn.Module): PyTorch model to be evaluated.\n",
    "    loss_fn (callable): Loss function.\n",
    "    cumulative_metrics (CumulativeMetrics): Instance of CumulativeMetrics for tracking metrics.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Average loss and average accuracy for the test dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    batch_losses = []\n",
    "    cumulative_metrics.reset()\n",
    "\n",
    "    if mode == \"Testing\":\n",
    "        with torch.no_grad():\n",
    "            for _, (X, y, _) in enumerate(dataloader):\n",
    "                X, y = X.to(device), y.to(device).unsqueeze(1)\n",
    "                y = y.to(torch.float32)\n",
    "\n",
    "                pred = model(X)\n",
    "                \n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                batch_losses.append(loss.item())\n",
    "                cumulative_metrics.update(pred, y)\n",
    "        \n",
    "        avg_loss = sum(batch_losses) / len(batch_losses)    \n",
    "        performance_metrics = cumulative_metrics.get_cumulative_metrics()\n",
    "\n",
    "    \n",
    "    if mode == \"Validation\":\n",
    "        with torch.no_grad():\n",
    "            for _, (X, y, _) in enumerate(dataloader):\n",
    "                X, y = X.to(device), y.to(device).unsqueeze(1)\n",
    "                y = y.to(torch.float32)\n",
    "\n",
    "                pred = model(X)\n",
    "                \n",
    "                loss = loss_fn(pred, y)\n",
    "\n",
    "                batch_losses.append(loss.item())\n",
    "                cumulative_metrics.update(pred, y)\n",
    "        \n",
    "        avg_loss = sum(batch_losses) / len(batch_losses)    \n",
    "        performance_metrics = cumulative_metrics.get_cumulative_metrics()\n",
    "    \n",
    "    return avg_loss, performance_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CumulativeMetrics:\n",
    "    def __init__(self):\n",
    "        # Initialize torchmetrics for binary classification\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"binary\").to(device)\n",
    "        self.precision = torchmetrics.Precision(task=\"binary\", average=\"macro\").to(device)\n",
    "        self.recall = torchmetrics.Recall(task=\"binary\", average=\"macro\").to(device)\n",
    "        self.f1_score = torchmetrics.F1Score(task=\"binary\", average=\"macro\").to(device)\n",
    "\n",
    "        # For scikit-learn metrics, we'll store the true and predicted values for each batch\n",
    "        self.y_true_all = []\n",
    "        self.y_pred_all = []\n",
    "        self.y_score_all = []\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset torchmetrics accumulators\n",
    "        self.cum_acc = 0.0\n",
    "        self.cum_prec = 0.0\n",
    "        self.cum_rec = 0.0\n",
    "        self.cum_f1 = 0.0\n",
    "        self.num_batches = 0\n",
    "        \n",
    "        # Reset true and predicted values lists for sklearn\n",
    "        self.y_true_all = []\n",
    "        self.y_pred_all = []\n",
    "        self.y_score_all = []\n",
    "\n",
    "    def update(self, y_pred: torch.Tensor, y_true: torch.Tensor):\n",
    "        # For binary classification, y_true is already a class label (0 or 1)\n",
    "        y_pred_class = torch.round(torch.sigmoid(y_pred)).int()  # Get predicted class by rounding sigmoid output\n",
    "\n",
    "        # Append predictions and true labels for scikit-learn metrics later\n",
    "        self.y_true_all.extend(y_true.cpu().numpy())\n",
    "        self.y_pred_all.extend(y_pred_class.cpu().numpy())\n",
    "        self.y_score_all.extend(torch.sigmoid(y_pred).detach().cpu().numpy())  # Probabilities/logits for AUC\n",
    "\n",
    "        # Update cumulative torchmetrics\n",
    "        acc = self.accuracy(y_pred_class, y_true).item()\n",
    "        prec = self.precision(y_pred_class, y_true).item()\n",
    "        rec = self.recall(y_pred_class, y_true).item()\n",
    "        f1 = self.f1_score(y_pred_class, y_true).item()\n",
    "\n",
    "        self.cum_acc += acc\n",
    "        self.cum_prec += prec\n",
    "        self.cum_rec += rec\n",
    "        self.cum_f1 += f1\n",
    "        self.num_batches += 1\n",
    "\n",
    "    def get_cumulative_metrics(self):\n",
    "        avg_acc = self.cum_acc / self.num_batches\n",
    "        avg_prec = self.cum_prec / self.num_batches\n",
    "        avg_rec = self.cum_rec / self.num_batches\n",
    "        avg_f1 = self.cum_f1 / self.num_batches\n",
    "\n",
    "        # Ensure y_true_all contains basic data types before using set\n",
    "        y_true_list = [int(val) for val in self.y_true_all]\n",
    "\n",
    "        # Compute AUC using sklearn\n",
    "        if len(self.y_score_all) > 0 and len(set(y_true_list)) > 1:\n",
    "            auc = roc_auc_score(self.y_true_all, self.y_score_all)\n",
    "        else:\n",
    "            auc = None  # If no valid score or only one class present\n",
    "\n",
    "        performance_metrics = {\n",
    "            \"Accuracy\": avg_acc,\n",
    "            \"Precision\": avg_prec,\n",
    "            \"Recall\": avg_rec,\n",
    "            \"F1 Score\": avg_f1,\n",
    "            \"AUC\": auc,\n",
    "        }        \n",
    "        return performance_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "MobileNetV2                                        --\n",
      "â”œâ”€Sequential: 1-1                                  --\n",
      "â”‚    â””â”€Conv2dNormActivation: 2-1                   --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-1                            864\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-2                       64\n",
      "â”‚    â”‚    â””â”€ReLU6: 3-3                             --\n",
      "â”‚    â””â”€InvertedResidual: 2-2                       --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-4                        896\n",
      "â”‚    â””â”€InvertedResidual: 2-3                       --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-5                        5,136\n",
      "â”‚    â””â”€InvertedResidual: 2-4                       --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-6                        8,832\n",
      "â”‚    â””â”€InvertedResidual: 2-5                       --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-7                        10,000\n",
      "â”‚    â””â”€InvertedResidual: 2-6                       --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-8                        14,848\n",
      "â”‚    â””â”€InvertedResidual: 2-7                       --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-9                        14,848\n",
      "â”‚    â””â”€InvertedResidual: 2-8                       --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-10                       21,056\n",
      "â”‚    â””â”€InvertedResidual: 2-9                       --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-11                       54,272\n",
      "â”‚    â””â”€InvertedResidual: 2-10                      --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-12                       54,272\n",
      "â”‚    â””â”€InvertedResidual: 2-11                      --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-13                       54,272\n",
      "â”‚    â””â”€InvertedResidual: 2-12                      --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-14                       66,624\n",
      "â”‚    â””â”€InvertedResidual: 2-13                      --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-15                       118,272\n",
      "â”‚    â””â”€InvertedResidual: 2-14                      --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-16                       118,272\n",
      "â”‚    â””â”€InvertedResidual: 2-15                      --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-17                       155,264\n",
      "â”‚    â””â”€InvertedResidual: 2-16                      --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-18                       320,000\n",
      "â”‚    â””â”€InvertedResidual: 2-17                      --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-19                       320,000\n",
      "â”‚    â””â”€InvertedResidual: 2-18                      --\n",
      "â”‚    â”‚    â””â”€Sequential: 3-20                       473,920\n",
      "â”‚    â””â”€Conv2dNormActivation: 2-19                  --\n",
      "â”‚    â”‚    â””â”€Conv2d: 3-21                           409,600\n",
      "â”‚    â”‚    â””â”€BatchNorm2d: 3-22                      2,560\n",
      "â”‚    â”‚    â””â”€ReLU6: 3-23                            --\n",
      "â”œâ”€Sequential: 1-2                                  --\n",
      "â”‚    â””â”€Dropout: 2-20                               --\n",
      "â”‚    â””â”€Linear: 2-21                                1,281\n",
      "===========================================================================\n",
      "Total params: 2,225,153\n",
      "Trainable params: 2,225,153\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load MobileNetV2 with pretrained weights disabled\n",
    "# mbnetv2 = models.mobilenet_v2(weights=\"IMAGENET1K_V2\")\n",
    "mbnetv2 = models.mobilenet_v2(weights=None)\n",
    "\n",
    "# Modify the classifier to output 5 classes (corresponding to the severity levels)\n",
    "mbnetv2.classifier[1] = torch.nn.Linear(in_features=1280, out_features=1)\n",
    "mbnetv2 = mbnetv2.to(device)\n",
    "\n",
    "# Print the model summary\n",
    "print(summary(mbnetv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: 603 \tTest Dataset: 107\n"
     ]
    }
   ],
   "source": [
    "# Assuming `CumulativeMetrics` is already implemented elsewhere\n",
    "cumulative_metrics = CumulativeMetrics()  # Instance to track metrics (accuracy, precision, etc.)\n",
    "\n",
    "# Define any data augmentations or transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,192)),\n",
    "    transforms.RandomHorizontalFlip(p=np.random.rand()),\n",
    "    transforms.RandomVerticalFlip(p=np.random.rand()),\n",
    "    transforms.RandomRotation(degrees=np.random.randint(0,360)),\n",
    "    transforms.RandomAffine(degrees=np.random.randint(0,360)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom dataset class\n",
    "class DRImageDataset(Dataset):\n",
    "    def __init__(self, dir, df, transform=None):\n",
    "        self.dir = dir\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = row['IMAGE_ID']\n",
    "        img_folder = row['REMARK']\n",
    "        img_path = os.path.join(self.dir, img_folder, img_id + \".png\")\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = torch.tensor(row['REMARK_ONEHOT'], dtype=torch.int64)\n",
    "        descriptor = img_folder\n",
    "        \n",
    "        return img, label, descriptor\n",
    "\n",
    "# Load the dataset\n",
    "image_dataset = DRImageDataset(data_dir, data_sheet, transform=transform)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(image_dataset, test_size=0.15, shuffle=True)\n",
    "print(f\"Train Dataset: {len(train_dataset)} \\tTest Dataset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each fold\n",
    "EPOCHS = 150\n",
    "FOLDS = 5\n",
    "\n",
    "# 5-fold cross-validation setup\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = mbnetv2  # Your model instance\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()  # Binary cross-entropy loss (modify according to your task)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=10e-4)  # Adam optimizer (example)\n",
    "\n",
    "# Path where the model with the best precision is saved\n",
    "weights_path = \"C:\\\\Users\\\\sebastian.cruz6\\\\Workspace\\\\Research\\\\CAWT-URFI\\\\cp-anemia-detection\\\\notebooks\\\\weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_val_f1score = -float('inf')  # Initialize with a very low value\n",
    "\n",
    "# train_metrics_df = []\n",
    "# val_metrics_df = []\n",
    "\n",
    "# for epochs in range(EPOCHS):\n",
    "#     print(f\"\\nEpoch {epochs+1}/{EPOCHS}\")\n",
    "#     fold = 1\n",
    "#     fold_best_train_f1score = -float('inf')\n",
    "\n",
    "#     for train_idx, val_idx in kf.split(train_dataset):\n",
    "#         # Create subset datasets for training and validation\n",
    "#         train_subset = Subset(image_dataset, train_idx)\n",
    "#         val_subset = Subset(image_dataset, val_idx)\n",
    "\n",
    "#         # Create data loaders\n",
    "#         train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "#         val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "#         if fold == FOLDS:\n",
    "#             # Validation loop\n",
    "#             avg_val_loss, val_metrics = eval(val_loader, model, loss_fn, mode=\"Validation\", cumulative_metrics=cumulative_metrics)\n",
    "#             avg_val_accuracy, avg_val_precision, avg_val_recall, avg_val_f1, avg_val_auc = val_metrics.values()\n",
    "\n",
    "#             print(f\"\\nValidation: \\tFold {fold} - Loss: {avg_val_loss:.4f}, Accuracy: {avg_val_accuracy:.4f}, Precision: {avg_val_precision:.4f}, Recall: {avg_val_recall:.4f}, F1 Score: {avg_val_f1:.4f}, AUC Score: {avg_val_auc:.4f}\")\n",
    "\n",
    "#             # Save the best model based on validation precision\n",
    "#             if avg_val_f1 > best_val_f1score:\n",
    "#                 best_val_f1score = avg_val_f1\n",
    "                \n",
    "#                 val_metrics_dict = {**{\"Loss\":avg_val_loss}, **val_metrics}\n",
    "#                 val_metrics_df.append(val_metrics_dict)\n",
    "\n",
    "#                 torch.save(mbnetv2.state_dict(), f'{weights_path}\\\\mbnetv2_best_f1score.pth')\n",
    "#                 print(f\"Model with best precision during Validation saved at epoch {epochs + 1} with F1 Score of {best_val_f1score:.4f}\")\n",
    "#         # \"\"\"\n",
    "#         # Implement early stopping here as an elif statement\n",
    "#         # \"\"\"\n",
    "#         else:\n",
    "#             # Training loop\n",
    "#             avg_train_loss, train_metrics = train(train_loader, model, loss_fn, optimizer, cumulative_metrics)\n",
    "#             avg_train_accuracy, avg_train_precision, avg_train_recall, avg_train_f1, avg_train_auc = train_metrics.values()\n",
    "\n",
    "#             if avg_train_f1 > fold_best_train_f1score:\n",
    "#                 fold_best_train_f1score = avg_train_f1\n",
    "\n",
    "#                 print(f\"Training: \\tFold {fold} - Loss: {avg_train_loss:.4f}, Accuracy: {avg_train_accuracy:.4f}, Precision: {avg_train_precision:.4f}, Recall: {avg_train_recall:.4f}, F1 Score: {avg_train_f1:.4f}, AUC Score: {avg_train_auc:.4f}\")\n",
    "#                 train_metrics_dict = {**{\"Loss\":avg_train_loss}, **train_metrics}\n",
    "#                 train_metrics_df.append(train_metrics_dict)\n",
    "\n",
    "#         # Reset metrics and model (if needed) for next fold\n",
    "#         cumulative_metrics.reset()\n",
    "\n",
    "#         fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: \tLoss: 0.2361, Accuracy: 0.9155, Precision: 0.9443, Recall: 0.9304, F1 Score: 0.9371, AUC Score: 0.9746\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "mbnetv2.load_state_dict(torch.load(f'{weights_path}\\\\mbnetv2_weights_09182024.pth', weights_only=True))\n",
    "\n",
    "test_loss, test_performance_metrics = eval(test_loader, mbnetv2, loss_fn, 'Testing', CumulativeMetrics())\n",
    "test_accuracy, test_precision, test_recall, test_f1, test_auc = test_performance_metrics.values()\n",
    "print(f\"Testing: \\tLoss: {test_loss:.4f}, Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1 Score: {test_f1:.4f}, AUC Score: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2 w/ Pre-trained Weights (ImageNet1K) Trained on CP-AnemiC Dataset: 9.12 MB\n"
     ]
    }
   ],
   "source": [
    "def print_model_size(title, mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    print(title, \"%.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6))\n",
    "    os.remove('tmp.pt')\n",
    "\n",
    "print_model_size(\"MobileNetV2 w/ Pre-trained Weights (ImageNet1K) Trained on CP-AnemiC Dataset:\", mbnetv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cawt-urfi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

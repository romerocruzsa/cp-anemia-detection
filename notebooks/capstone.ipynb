{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for file handling, data manipulation, and visualization\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import libraries for working with images and transformations\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "\n",
    "# Import PyTorch modules for model building, data handling, and evaluation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.models.quantization as quant_models\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchinfo import summary\n",
    "\n",
    "# Import libraries for machine learning metrics and model evaluation\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, mean_squared_error, mean_absolute_error, r2_score\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set the seed.\n",
    "seed = 42\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/Users/romerocruzsa/Workspace/Projects/Research/cp-anemia-detection/data/cp-anemia/\"\n",
    "weights_dir=\"/Users/romerocruzsa/Workspace/Projects/Research/cp-anemia-detection/notebooks/weights\"\n",
    "anemic_dir=data_dir+\"/Anemic\"\n",
    "non_anemic_dir=data_dir+\"/Non-anemic\"\n",
    "signature = \"02042024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sheet_path = data_dir+\"Anemia_Data_Collection_Sheet.csv\"\n",
    "data_sheet = pd.read_csv(data_sheet_path)\n",
    "display(data_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping diagnosis to severity\n",
    "severity_mapping = {\n",
    "    \"Non-Anemic\": 0,\n",
    "    \"Mild\": 1,\n",
    "    \"Moderate\": 2,\n",
    "    \"Severe\": 3,\n",
    "}\n",
    "\n",
    "data_sheet['Severity'] = data_sheet['Severity'].map(severity_mapping)\n",
    "display(data_sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentations or transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 192)),\n",
    "    transforms.RandomHorizontalFlip(p=np.random.rand()),\n",
    "    transforms.RandomVerticalFlip(p=np.random.rand()),\n",
    "    transforms.RandomRotation(degrees=np.random.randint(0, 360)),\n",
    "    transforms.RandomAffine(degrees=np.random.randint(0, 360)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Custom dataset class\n",
    "class CPAnemiCDataset(Dataset):\n",
    "    def __init__(self, dir, df, transform=None):\n",
    "        self.dir = dir\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = row['IMAGE_ID']\n",
    "        img_folder = row['REMARK']\n",
    "        img_path = os.path.join(self.dir, img_folder, img_id + \".png\")\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        multiclass_label = torch.tensor(row['Severity'])\n",
    "        hb_level = torch.tensor(row['HB_LEVEL'])\n",
    "\n",
    "        return img, multiclass_label, hb_level\n",
    "\n",
    "    # Load the dataset\n",
    "image_dataset = CPAnemiCDataset(data_dir, data_sheet, transform=transform)\n",
    "train_dataset, test_dataset = train_test_split(image_dataset, test_size=0.20, shuffle=True)\n",
    "\n",
    "print(f\"Image Dataset Size (All): {len(image_dataset)}, \\\n",
    "        Train Size: {len(train_dataset)}, \\\n",
    "        Test Size: {len(test_dataset)}\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default device\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Check for CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU.\")\n",
    "\n",
    "print(f\"Selected device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    model_size = \"Model Size: %.2f MB\" %(os.path.getsize(\"tmp.pt\")/1e6)\n",
    "    os.remove('tmp.pt')\n",
    "    return model_size\n",
    "\n",
    "# Static Weighting Function. Set eta_class to desired importance (Classification > .5, Regression < .5, Equal == .5)\n",
    "def sw_loss(loss_class, loss_reg, eta_class=0.5):\n",
    "    eta_reg = 1 - eta_class\n",
    "    total_loss = (eta_class * loss_class) + (eta_reg * loss_reg)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn_class, loss_fn_reg, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # print(\"prob_class_0 | prob_class_1 | prob_class_2 | prob_class_3 | highest_prob_class | hb_estimate\")\n",
    "\n",
    "    for _, (img, multiclass, hb_level) in enumerate(dataloader):\n",
    "        img = img.to(device)\n",
    "        multiclass = multiclass.to(device)\n",
    "        hb_level = hb_level.to(device).unsqueeze(1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass (model outputs both classification and regression)\n",
    "        class_pred, reg_pred = model(img)\n",
    "\n",
    "        # Compute losses\n",
    "        loss_class = loss_fn_class(class_pred, multiclass)\n",
    "        loss_reg = loss_fn_reg(reg_pred, hb_level)\n",
    "        loss = sw_loss(loss_class, loss_reg, 0.7)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track total loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Compute probabilities\n",
    "        class_probs = F.softmax(class_pred, dim=1)\n",
    "        highest_prob_class = torch.argmax(class_probs, dim=1)\n",
    "\n",
    "        # Track accuracy\n",
    "        correct += (highest_prob_class == multiclass).sum().item()\n",
    "        total_samples += multiclass.size(0)\n",
    "\n",
    "        # Print probabilities, predicted class, and Hb estimate\n",
    "        # for i in range(class_probs.size(0)):\n",
    "        #     print(f\"{class_probs[i, 0]:.4f} | {class_probs[i, 1]:.4f} | {class_probs[i, 2]:.4f} | {class_probs[i, 3]:.4f} | {highest_prob_class[i].item()} | {reg_pred[i].item():.2f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total_samples\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(dataloader, model, loss_fn_class, loss_fn_reg):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # print(\"prob_class_0 | prob_class_1 | prob_class_2 | prob_class_3 | highest_prob_class | hb_estimate\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _, (img, multiclass, hb_level) in enumerate(dataloader):\n",
    "            img = img.to(device)\n",
    "            multiclass = multiclass.to(device)\n",
    "            hb_level = hb_level.to(device).unsqueeze(1).float()\n",
    "\n",
    "            # Forward pass (model outputs both classification and regression)\n",
    "            class_pred, reg_pred = model(img)\n",
    "\n",
    "            # Compute losses\n",
    "            loss_class = loss_fn_class(class_pred, multiclass)\n",
    "            loss_reg = loss_fn_reg(reg_pred, hb_level)\n",
    "            loss = sw_loss(loss_class, loss_reg, 0.7)\n",
    "\n",
    "            # Track total loss\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute probabilities\n",
    "            class_probs = F.softmax(class_pred, dim=1)\n",
    "            highest_prob_class = torch.argmax(class_probs, dim=1)\n",
    "\n",
    "            # Track accuracy\n",
    "            correct += (highest_prob_class == multiclass).sum().item()\n",
    "            total_samples += multiclass.size(0)\n",
    "\n",
    "            # # Print probabilities, predicted class, and Hb estimate\n",
    "            # for i in range(class_probs.size(0)):\n",
    "            #     print(f\"{class_probs[i, 0]:.4f} | {class_probs[i, 1]:.4f} | {class_probs[i, 2]:.4f} | {class_probs[i, 3]:.4f} | {highest_prob_class[i].item()} | {reg_pred[i].item():.2f}\")\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total_samples\n",
    "\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetMultiOutput(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MobileNetMultiOutput, self).__init__()\n",
    "        self.mobilenet = models.mobilenet_v2(pretrained=False)\n",
    "        num_ftrs = self.mobilenet.classifier[1].in_features\n",
    "        self.mobilenet.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(num_ftrs, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 5)  # 4-class classification + 1 regression output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.mobilenet(x)\n",
    "        class_output = output[:, :4]  # First 4 values = class probabilities\n",
    "        reg_output = output[:, 4]  # Last value = Hb level estimate\n",
    "        return class_output, reg_output  # Return as two separate outputs\n",
    "\n",
    "# Load the modified MobileNet\n",
    "model = MobileNetMultiOutput().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "FOLDS = 5\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Ensure dataset exists (Modify as needed)\n",
    "image_dataset = train_dataset  # Assuming train_dataset is defined\n",
    "\n",
    "# Initialize model and loss functions\n",
    "model = MobileNetMultiOutput().to(device)\n",
    "\n",
    "loss_fn_class = torch.nn.CrossEntropyLoss()  # Multi-class classification loss\n",
    "loss_fn_reg = torch.nn.MSELoss()  # Regression loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 5-Fold Cross Validation\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Directory to save the best model\n",
    "weights_dir = \"model_weights\"\n",
    "os.makedirs(weights_dir, exist_ok=True)\n",
    "\n",
    "best_val_acc = -float('inf')  # Track best validation accuracy\n",
    "train_metrics_df = []\n",
    "val_metrics_df = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    fold = 1\n",
    "\n",
    "    for train_idx, val_idx in kf.split(range(len(image_dataset))):  # FIX: Ensure correct splitting\n",
    "        train_subset = Subset(image_dataset, train_idx)\n",
    "        val_subset = Subset(image_dataset, val_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        if fold == FOLDS:\n",
    "            # Validation phase\n",
    "            avg_val_loss, val_acc = eval(val_loader, model, loss_fn_class, loss_fn_reg)\n",
    "\n",
    "            print(f\"\\nValidation: Fold {fold} - Loss: {avg_val_loss:.4f}, Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "            # Save model with the best validation accuracy\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                val_metrics_dict = {\"Loss\": avg_val_loss, \"Accuracy\": val_acc}\n",
    "                val_metrics_df.append(val_metrics_dict)\n",
    "                torch.save(model.state_dict(), f\"{weights_dir}/model_best_accuracy.pth\")\n",
    "                print(f\"Best model saved with Accuracy: {best_val_acc:.4f}\")\n",
    "\n",
    "        else:\n",
    "            # Training phase\n",
    "            avg_train_loss, train_acc = train(train_loader, model, loss_fn_class, loss_fn_reg, optimizer)\n",
    "\n",
    "            print(f\"Training: Fold {fold} - Loss: {avg_train_loss:.4f}, Accuracy: {train_acc:.4f}\")\n",
    "\n",
    "            train_metrics_dict = {\"Loss\": avg_train_loss, \"Accuracy\": train_acc}\n",
    "            train_metrics_df.append(train_metrics_dict)\n",
    "\n",
    "        fold += 1  # Move to next fold\n",
    "\n",
    "# Ensure `get_model_size()` exists or remove this line\n",
    "print(get_model_size(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cawt-urfi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
